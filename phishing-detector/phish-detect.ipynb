{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b15b557",
   "metadata": {},
   "source": [
    "# AI Phishing URL Detector in Python\n",
    "source: https://www.activestate.com/blog/phishing-url-detection-with-python-and-ml/\n",
    "\n",
    "## 1 - Identifying Fradulent URLs\n",
    "A **fraudulent domain** or phishing domain is a URL scheme that looks suspicious. The URL:\n",
    "* is misspelled\n",
    "* points to the wrong top-level domain\n",
    "* a combo of a valid and fraudulent URL\n",
    "* is incredibly long\n",
    "* is just an IP address\n",
    "* has a low [pagerank](https://en.wikipedia.org/wiki/PageRank)\n",
    "* has a young domain page, and/or\n",
    "* ranks poorly on the [Alexa Top 1 Million Sites](https://www.alexa.com/topsites)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badaa214",
   "metadata": {},
   "source": [
    "### Dataset and Criteria\n",
    "For this project, I will use a [dataset from The University of California, Irvine](https://archive.ics.uci.edu/ml/datasets/Phishing+Websites#) identifying fraudulent vs. valid URLs to train my model. This is a old dataset, but the features are still valid today. Feature sets are divided into 4 main categories:\n",
    "1. *Address Bar-Based* - features extracted from the URL itself. This may include:\n",
    "    * URL length > 54 characters\n",
    "    * contains an IP address\n",
    "    * uses an URL shortening service like TinyURL or Bitly\n",
    "    * employs redirection\n",
    "    * adding a prefix or suffix separated by \"-\" to the domain\n",
    "    * having sub-domain and multi-sub-domains\n",
    "    * existence of HTTPS\n",
    "    * domain registration age\n",
    "    * favicon loading from a different domain\n",
    "    * using a non-standard port\n",
    "2. *Abnormal Features* may include:\n",
    "    * loading images in the body of the page from a different URL\n",
    "    * minimal use of meta tags\n",
    "    * the use of a Server Form Handler (SFH), which processes data sent to an HTML form\n",
    "    * submitting information to email\n",
    "    * an abnormal URL\n",
    "3. *HTML and JavaScript-Based Features* may include:\n",
    "    * website forwarding \n",
    "    * status bar customization normally using JavaScript to display a fake URL \n",
    "    * disabling the ability to right-click so users can’t view page source code\n",
    "    * using pop-up windows\n",
    "    * iFrame redirection\n",
    "4. *Domain-Based Features* may include:\n",
    "    * unusually young domains\n",
    "    * suspicious DNS record\n",
    "    * low volume of website traffic\n",
    "    * PageRank (95% of phishing webpages have no PageRank)\n",
    "    * whether the site has been indexed by Google"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80d19de",
   "metadata": {},
   "source": [
    "## 2 - Building A Decision Tree\n",
    "For my machine learning algorithm, I will need a decision tree classifier to help me determine whether a URL is valid or not. I downloaded the UC Irvine dataset and explored its contents. The feature list contains:\n",
    "* having_IP_Address  { -1,1 }\n",
    "* URL_Length   { 1,0,-1 }\n",
    "* Shortining_Service { 1,-1 }\n",
    "* having_At_Symbol   { 1,-1 }\n",
    "* double_slash_redirecting { -1,1 }\n",
    "* Prefix_Suffix  { -1,1 }\n",
    "* having_Sub_Domain  { -1,0,1 }\n",
    "* SSLfinal_State  { -1,1,0 }\n",
    "* Domain_registeration_length { -1,1 }\n",
    "* Favicon { 1,-1 }\n",
    "* port { 1,-1 }\n",
    "* HTTPS_token { -1,1 }\n",
    "* Request_URL  { 1,-1 }\n",
    "* URL_of_Anchor { -1,0,1 }\n",
    "* Links_in_tags { 1,-1,0 }\n",
    "* SFH  { -1,1,0 }\n",
    "* Submitting_to_email { -1,1 }\n",
    "* Abnormal_URL { -1,1 }\n",
    "* Redirect  { 0,1 }\n",
    "* on_mouseover  { 1,-1 }\n",
    "* RightClick  { 1,-1 }\n",
    "* popUpWidnow  { 1,-1 }\n",
    "* Iframe { 1,-1 }\n",
    "* age_of_domain  { -1,1 }\n",
    "* DNSRecord   { -1,1 }\n",
    "* web_traffic  { -1,0,1 }\n",
    "* Page_Rank { -1,1 }\n",
    "* Google_Index { 1,-1 }\n",
    "* Links_pointing_to_page { 1,0,-1 }\n",
    "* Statistical_report { -1,1 }\n",
    "\n",
    "The Result designates whether the URL is valid or not.\n",
    "* Result  { -1,1 }\n",
    "\n",
    "where -1 denotes an invalid URL and 1 is a valid URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171fc353",
   "metadata": {},
   "source": [
    "Now is the code. First, I'll load the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to perform operations on dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io.arff import loadarff\n",
    "# ML model\n",
    "## dev note: install scikit-learn instead of sklearn, as it's deprecated\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# visualization\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as pyplt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c948207",
   "metadata": {},
   "source": [
    "I took a moment to download any libaries that weren't installed on my machine, which was all of them, as this is my first time working with ML on my own environment. Next is reading and spliting the dataset. I had to make some edits to the original, as the dataset was an `.arff` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef25dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = loadarff('Training Dataset.arff')\n",
    "df = pd.DataFrame(raw_data[0])\n",
    "dot_file = '.../tree.dot'\n",
    "confusion_matrix_file = '.../confusion_matrix.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddef69e",
   "metadata": {},
   "source": [
    "And then printing the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8951b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0ef0dd",
   "metadata": {},
   "source": [
    "This dataset contains 5 rows and 31 columns, where each column contains a value for each of the attributes discussed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d8767e",
   "metadata": {},
   "source": [
    "## 3 - Train the Model\n",
    "The first step in training a machine learning model is to split the dataset into testing and training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ec900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5d1260",
   "metadata": {},
   "source": [
    "Since the dataset contains boolean data, it’s always best to use a Decision Tree, RandomForest Classifier or Logistic Regression algorithm since these models work best for classification. In this case, the OP (see source) chose to work with a Decision Tree, because it’s straightforward and generally gives the best results when trying to classify data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac55687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(Xtrain, ytrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
